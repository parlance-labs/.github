# ğŸ‘‹ Hey there! We're Parlance Labs

We're a group of AI engineers led by [Hamel Husain](https://hamel.dev) who help companies figure out if their AI is actually working (spoiler: often it's not) and how to make it better.

## What we're all about

Here's what drives our approach:

- We build systems for [systematic AI evaluation](https://hamel.dev/blog/posts/evals/) (because how else will you know if your AI is doing anything useful?)
- We're data-obsessed and pragmatic. We teach you [processes that have worked](https://hamel.dev/blog/posts/field-guide/) more than 30 AI implementations.
- We've developed methods to make sure your AI can [provide business value and produce results you can trust](https://hamel.dev/blog/posts/llm-judge/).
  
## Weâ€™re the consultancy who wants you to "fire usâ€

Here's something different about us: **we don't want you to have a long-term dependency on us**. Weâ€™re not here to pitch you on new models, frameworks, or expensive infrastructure. We *are* here to teach you methods to experiment faster and systematically improve your systems, regardless of your domain or use-case.

We don't chase recurring revenue or sell maintenance contracts - we think that creates perverse incentives.  Instead, we work alongside your team, transfer knowledge, and build capabilities so that when we leave, you have:
- The skills to evaluate your AI systems
- Processes for continuous improvement
- Independence from consultants (including us!)

## Find us around the internet

- ğŸŒ [parlance-labs.com](https://parlance-labs.com) - More about what we do
- ğŸ“ [hamel.dev](https://hamel.dev) - Hamel's blog with deeper technical dives
- ğŸ¦ [@HamelHusain](https://x.com/HamelHusain) - Hamel's Twitter/X where he posts about AI, data, and occasionally rants about LLM frameworks

