# ğŸ‘‹ Hey there! We're Parlance Labs

We're a group of AI engineers led by [Hamel Husain](https://hamel.dev) who help companies figure out if their AI is actually working (spoiler: often it's not) and how to make it better.

## What we're all about

Here's what drives our approach:

- We build systems for [systematic AI evaluation](https://hamel.dev/blog/posts/evals/) (because how else will you know if your AI is doing anything useful?)
- We're data-obsessed and pragmatic. We teach you [processes that have worked across 30+ AI implementations](https://hamel.dev/blog/posts/field-guide/), and will [work for you too](https://parlance-labs.com), regardless of your use-case or domain.
- We've developed methods to make sure our systems [provide business value and maintain trust](https://hamel.dev/blog/posts/llm-judge/).
## We teach you how to fish

Here's something different about us: **we don't want you to have a long-term dependency on us**.

Our consultancy model is explicitly designed to make ourselves unnecessary. We don't chase recurring revenue or sell maintenance contracts - we think that creates perverse incentives.

Instead, we work alongside your team, transfer knowledge, and build capabilities so that when we leave, you have:
- The skills to evaluate your AI systems
- Processes for continuous improvement
- Independence from consultants (including us!)

When we succeed, you don't need us anymore. That's exactly how we want it.

## Find us around the internet

- ğŸŒ [parlance-labs.com](https://parlance-labs.com) - More about what we do
- ğŸ“ [hamel.dev](https://hamel.dev) - Hamel's blog with deeper technical dives
- ğŸ¦ [@HamelHusain](https://x.com/HamelHusain) - Hamel's Twitter/X where he posts about AI, data, and occasionally rants about LLM frameworks

